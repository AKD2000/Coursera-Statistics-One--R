
1
00:00:01,290 --> 00:00:03,650
Hi, and welcome to Statistics One lab
four.

2
00:00:03,650 --> 00:00:07,550
The goals of today's lab are to read

3
00:00:07,550 --> 00:00:10,360
a data file into R, which we've done
already.

4
00:00:10,360 --> 00:00:13,194
Again, print summary statistics, which
we've done.

5
00:00:13,194 --> 00:00:17,286
We'll do correlation analyses which we
covered last week but then we'll

6
00:00:17,286 --> 00:00:21,820
also do regression analyses, which is the
main topic of this week.

7
00:00:21,820 --> 00:00:23,932
And you'll see that we'll do, first

8
00:00:23,932 --> 00:00:27,430
we'll do a regression analyses yielding
unstandardized

9
00:00:27,430 --> 00:00:29,057
regression coefficients.

10
00:00:29,057 --> 00:00:30,799
And then we'll do a regression

11
00:00:30,799 --> 00:00:34,528
analysis giving us the standardized
regression coefficients.

12
00:00:34,528 --> 00:00:36,508
And you'll see it's really simple

13
00:00:36,508 --> 00:00:40,092
manipulation to go from unstandardized to
standardized.

14
00:00:40,092 --> 00:00:41,982
And the example this week is a little

15
00:00:41,982 --> 00:00:46,560
different it's actually much simpler,
there's just three variables.

16
00:00:46,560 --> 00:00:53,060
So, the example is, a correlational study
investigating predictors of physical

17
00:00:53,060 --> 00:00:55,570
endurance in healthy adults.

18
00:00:55,570 --> 00:01:00,090
So, the outcome variable, y, is physical
endurance.

19
00:01:00,090 --> 00:01:01,770
And you'll see that it's just on an

20
00:01:01,770 --> 00:01:04,530
arbitrary scale, it's measured from zero
to 60.

21
00:01:04,530 --> 00:01:10,640
And the predictors, the x variables, are
age and number of years

22
00:01:10,640 --> 00:01:15,920
that the person has active, has been
actively engaged in exercise or sports.

23
00:01:15,920 --> 00:01:18,940
You'll see that the sample, which consists

24
00:01:18,940 --> 00:01:23,350
of 200 people, consists of people who are
pretty active.

25
00:01:23,350 --> 00:01:25,780
So we'll see that when we look at the
summary statistics.

26
00:01:27,270 --> 00:01:31,960
Again I've commented, commented out these,
these lines of code because I know I'm

27
00:01:31,960 --> 00:01:33,520
in the right working directory but just

28
00:01:33,520 --> 00:01:35,740
make sure you're in the right working
directory.

29
00:01:35,740 --> 00:01:40,270
Make sure your data file is spelled
correctly, there's

30
00:01:40,270 --> 00:01:43,000
been a lot of problems just downloading
data files.

31
00:01:43,000 --> 00:01:43,820
just make sure you're,

32
00:01:43,820 --> 00:01:46,240
you're, you're spelling your data file
correctly.

33
00:01:46,240 --> 00:01:49,750
Make sure you're downloading it into your
working directory.

34
00:01:50,760 --> 00:01:54,960
the only package we'll need for this lab
is the psych package.

35
00:01:54,960 --> 00:01:58,020
So, most of you should have that installed
already.

36
00:01:58,020 --> 00:01:59,520
but if you don't, if you're joining the

37
00:01:59,520 --> 00:02:02,940
class late you need to install the psych
package.

38
00:02:02,940 --> 00:02:05,720
Again, I've commented that out because
I've already done it.

39
00:02:05,720 --> 00:02:08,900
Okay, so let's go.
I start by loading

40
00:02:08,900 --> 00:02:13,500
the psych library and then I'm going to
read in the data

41
00:02:13,500 --> 00:02:18,273
file from that text file into a data frame
called PE.

42
00:02:18,273 --> 00:02:23,493
I'm hitting Cmd+Return, and then Cmd+1 to
go back to the console

43
00:02:23,493 --> 00:02:28,390
and good, it looks like there's no errors.
So let me just,

44
00:02:29,590 --> 00:02:33,970
let me just look at it.
I'll use the view, sorry, I'll use

45
00:02:33,970 --> 00:02:37,960
the edit function edit PE, you can use the
view function if you like.

46
00:02:39,032 --> 00:02:43,750
let me execute that, and the R Editor
comes up.

47
00:02:43,750 --> 00:02:46,070
if you're working in R studio you would
have already seen this.

48
00:02:47,270 --> 00:02:50,970
this is just a participant ID number which
is common

49
00:02:50,970 --> 00:02:56,680
just give people an arbitrary
identification number their age in years.

50
00:02:56,680 --> 00:02:59,060
Active years refers to the number of years
that they've

51
00:02:59,060 --> 00:03:03,230
been actively engaged in sports or in
exercise.

52
00:03:03,230 --> 00:03:06,379
And endurance again, is the score on an
arbitrary scale

53
00:03:06,379 --> 00:03:10,360
zero to 60 where higher scores indi,
indicate greater endurance.

54
00:03:12,430 --> 00:03:15,900
So now, let's move down through the code
for

55
00:03:15,900 --> 00:03:19,540
this lab and let's look at some summary
statistics.

56
00:03:19,540 --> 00:03:22,979
Give us an idea of what's in these
variables.

57
00:03:25,780 --> 00:03:27,690
So here are the summary statistics.

58
00:03:27,690 --> 00:03:30,750
You see that we have 200 subjects in, or

59
00:03:30,750 --> 00:03:35,080
participants if you like, in this in this
sample.

60
00:03:36,100 --> 00:03:41,130
And notice I didn't change participant ID
to a factor, I left

61
00:03:41,130 --> 00:03:44,830
it in there as integer, so R's reading
that in as an integer.

62
00:03:44,830 --> 00:03:47,490
if you don't want that in your summary
statistics table you

63
00:03:47,490 --> 00:03:50,586
could change that to a factor which we did
last week.

64
00:03:50,586 --> 00:03:51,353
so technically

65
00:03:51,353 --> 00:03:54,324
I should, I should get that out of there.

66
00:03:54,324 --> 00:03:56,756
but let's look at age, the mean age in

67
00:03:56,756 --> 00:03:59,810
this sample's about 49 and a half years
old.

68
00:04:01,120 --> 00:04:03,040
as I said, notice that this, this

69
00:04:03,040 --> 00:04:09,090
sample they're pretty healthy, athletic
physically fit bunch.

70
00:04:09,090 --> 00:04:13,080
There, they've been on average, actively
engaged in sports or

71
00:04:13,080 --> 00:04:16,385
physical fitness for 10.6 years, ten and a
half years.

72
00:04:16,385 --> 00:04:16,735
[LAUGH]

73
00:04:16,735 --> 00:04:23,274
at least in the US that's, that's pretty
atypical for a group of 200, 200 adults.

74
00:04:23,274 --> 00:04:27,660
so that will also help to explain some of
the odd correlations

75
00:04:27,660 --> 00:04:32,609
that you're about to see which is why I am
pointing it out.

76
00:04:32,609 --> 00:04:37,145
and they're average endurance score again,
the scale you'll

77
00:04:37,145 --> 00:04:40,989
see the minimum is three and the maximum
is 55.

78
00:04:40,989 --> 00:04:41,946
the scale's

79
00:04:41,946 --> 00:04:47,887
an arbitrary scale that we picked again,
we just made up data for this.

80
00:04:47,887 --> 00:04:52,930
it's from zero to 60 with higher scores
indicating greater endurance.

81
00:04:54,060 --> 00:04:56,436
So, let's go back to the script and let's

82
00:04:56,436 --> 00:05:00,130
run a correlation analysis just on those
three variables.

83
00:05:00,130 --> 00:05:05,208
So I'm doing core(PE that's the data frame
where the data are now.

84
00:05:05,208 --> 00:05:07,008
And I'm doing [2:4

85
00:05:07,008 --> 00:05:10,248
because I don't want to put participant ID

86
00:05:10,248 --> 00:05:14,800
in there, I just want the three main
variables.

87
00:05:14,800 --> 00:05:15,850
So I'll execute that.

88
00:05:17,440 --> 00:05:20,180
And here are the correlations.

89
00:05:20,180 --> 00:05:21,930
so the correlation between age and

90
00:05:21,930 --> 00:05:26,710
active years is positive, it's 0.33,
approximately.

91
00:05:27,780 --> 00:05:32,180
so the older you are, the more opportunity
you've had to

92
00:05:32,180 --> 00:05:37,990
be engaged in to be actively engaged in
sports, so that's why that's positive.

93
00:05:39,510 --> 00:05:42,040
And you'll notice that physical endurance
is not

94
00:05:42,040 --> 00:05:44,419
correlated with age, if anything it's
negatively correlated.

95
00:05:47,342 --> 00:05:50,340
again, you might think that's a little
odd.

96
00:05:50,340 --> 00:05:55,810
you would expect a, a sort of stronger
negative correlation, right.

97
00:05:55,810 --> 00:06:00,860
Because, as you go up in age, you should
be going down in physical endurance.

98
00:06:00,860 --> 00:06:05,360
But as I said, this is a sort of unique
sample because they're very active the

99
00:06:05,360 --> 00:06:10,250
average again, for active years was over
ten,

100
00:06:10,250 --> 00:06:11,930
it's like ten and a half, almost eleven.

101
00:06:13,040 --> 00:06:16,470
and you'll see, that's, that's accounting
for this, this

102
00:06:16,470 --> 00:06:19,190
lack of correlation here between age and
physical endurance.

103
00:06:20,380 --> 00:06:22,320
so then we have a correlation between

104
00:06:22,320 --> 00:06:24,510
active years and endurance, as you would
expect.

105
00:06:24,510 --> 00:06:29,430
So, the more people are engaged in, in

106
00:06:29,430 --> 00:06:33,800
active exercise or sports the better their
physical endurance.

107
00:06:33,800 --> 00:06:38,230
So let's go back to the script.
as we run larger

108
00:06:38,230 --> 00:06:42,420
correlation matrices, I think we did this
last week I like to use

109
00:06:42,420 --> 00:06:48,162
the round function, makes it a little
cleaner, so, I just put round around

110
00:06:48,162 --> 00:06:49,760
[LAUGH]

111
00:06:49,760 --> 00:06:50,560
that line of code.

112
00:06:52,490 --> 00:06:57,360
and then that'll just give me two decimal
places so just looks a little cleaner.

113
00:06:59,580 --> 00:07:03,220
we could also run the function cor.test
now that you've

114
00:07:03,220 --> 00:07:08,080
been exposed to this idea of null
hypothesis significance testing.

115
00:07:08,080 --> 00:07:10,010
I didn't run this last week in lab because

116
00:07:10,010 --> 00:07:14,310
we hadn't really encountered the idea of
significance testing yet.

117
00:07:14,310 --> 00:07:17,780
we're going to cover this idea a lot more
next week

118
00:07:17,780 --> 00:07:21,740
when we talk about the central limit
theorem in particular.

119
00:07:21,740 --> 00:07:25,740
but we could, for each of these, we could
just run a null

120
00:07:25,740 --> 00:07:27,180
hypothesis significance test.

121
00:07:27,180 --> 00:07:30,620
So that correlation between age and active
years,

122
00:07:30,620 --> 00:07:34,570
it was about 0.33, is it statistically
significant?

123
00:07:34,570 --> 00:07:38,450
Well if I run core.test R will tell me.

124
00:07:38,450 --> 00:07:44,040
So you can execute that one line of code,
go back to the console, and

125
00:07:44,040 --> 00:07:46,745
you'll see that R gives me this output

126
00:07:46,745 --> 00:07:50,368
it says, we're running a Pearson's
product-moment correlation,

127
00:07:50,368 --> 00:07:52,970
that's what core.test gives as the
default.

128
00:07:55,030 --> 00:07:59,906
it then gives me a t value of 4.9.
What's called degrees of

129
00:07:59,906 --> 00:08:06,160
freedom is DF, it's 198, it's the number
of subjects minus 2.

130
00:08:06,160 --> 00:08:09,330
and again, we'll talk a lot about why it's
that number

131
00:08:09,330 --> 00:08:12,240
next week and, and how you get this exact
p value.

132
00:08:12,240 --> 00:08:14,830
This p value is, this is stated in

133
00:08:14,830 --> 00:08:20,750
significant digits, so this is like
0.000001 so

134
00:08:20,750 --> 00:08:22,030
it's very, very low.

135
00:08:23,890 --> 00:08:27,170
which means we would reject the null
hypothesis

136
00:08:27,170 --> 00:08:29,770
that there's no relationship between age
and active

137
00:08:29,770 --> 00:08:33,250
years, that says here the true correlation
is

138
00:08:33,250 --> 00:08:35,510
not equal to zero is the alternative
hypothesis.

139
00:08:36,574 --> 00:08:39,790
it also gives a confidence interval, which
we'll talk about next week.

140
00:08:39,790 --> 00:08:46,060
So instead of reporting just the estimated
correlation,

141
00:08:46,060 --> 00:08:50,210
remember this is an estimate of the true
population correlation based on this

142
00:08:50,210 --> 00:08:56,970
sample, some statisticians suggest that we
should report confidence intervals.

143
00:08:56,970 --> 00:09:03,840
so this is our 95% confidence interval for
this correlation, it's about 0.2 to 0.45.

144
00:09:03,840 --> 00:09:07,190
you see that 0.33 sits right in the middle
of that interval.

145
00:09:07,190 --> 00:09:11,120
So this, we'll cover next week.
the correlation coefficient is known

146
00:09:11,120 --> 00:09:15,360
as a point estimate and this is known as
an interval estimate.

147
00:09:15,360 --> 00:09:16,810
This is our best estimate of what the

148
00:09:16,810 --> 00:09:21,230
true population correlation is between age
and active years.

149
00:09:21,230 --> 00:09:25,180
Remember, there's always going to be some
error associated with just a

150
00:09:25,180 --> 00:09:31,090
point estimate, this 0.33 because there's
always some degree of sampling error.

151
00:09:31,090 --> 00:09:34,580
Well, how much sampling error do, can we,
can we expect?

152
00:09:34,580 --> 00:09:36,210
Well, we try to estimate that

153
00:09:36,210 --> 00:09:38,460
by calculating standard error.

154
00:09:38,460 --> 00:09:40,840
And that's how this interval is
calculated, it's

155
00:09:40,840 --> 00:09:43,250
based on how much standard error we have.

156
00:09:43,250 --> 00:09:47,290
Remember, standard error is largely
determined by sample size.

157
00:09:47,290 --> 00:09:50,600
but I'm getting ahead of myself, we'll
talk more about all of that next week.

158
00:09:51,840 --> 00:09:53,610
Let's go back to the script.

159
00:09:53,610 --> 00:09:58,470
we could do that cor.test for each of the
other correlations.

160
00:09:58,470 --> 00:10:00,840
I'll do it for endurance and active years
and

161
00:10:00,840 --> 00:10:06,430
endurance and age.
And what we see is

162
00:10:06,430 --> 00:10:12,230
up here, this is for endurance and active
years, again we get this really

163
00:10:12,230 --> 00:10:18,904
pretty high t value, 4.86, and a very low
p value.

164
00:10:18,904 --> 00:10:22,500
that means that the probability of
obtaining this correlation given

165
00:10:22,500 --> 00:10:25,786
the assumption that the null hypothesis is
true, is very low,

166
00:10:25,786 --> 00:10:28,010
that's what that p value means.

167
00:10:28,010 --> 00:10:31,038
Again, we're going to get into this more
next week.

168
00:10:31,038 --> 00:10:34,780
again, it's about the same magnitude as
the, the one above it.

169
00:10:34,780 --> 00:10:37,240
And then of course, this one's not going
to be significant, right.

170
00:10:37,240 --> 00:10:42,350
So this one is negative 0.08, it's very
close to zero, so the

171
00:10:42,350 --> 00:10:47,590
t value is, is pretty low, it's negative
now because we have a negative

172
00:10:47,590 --> 00:10:52,870
correlation, so it's negative 1.12, say.

173
00:10:52,870 --> 00:10:57,930
and the p value is 0.23, so, that's not a
very low p value.

174
00:10:57,930 --> 00:11:00,540
to reject the null hypothesis we typically
want a p

175
00:11:00,540 --> 00:11:05,270
value less than say, 0.05 is a typical cut
off value.

176
00:11:05,270 --> 00:11:08,400
so here we would retain the null
hypothesis.

177
00:11:08,400 --> 00:11:10,730
And we could, we don't claim here, or

178
00:11:10,730 --> 00:11:13,940
we wouldn't claim here that there's a
significant correlation.

179
00:11:13,940 --> 00:11:17,090
Obviously, in this case it's, it's so
close to zero.

180
00:11:17,090 --> 00:11:17,910
Okay, let's go

181
00:11:17,910 --> 00:11:21,179
back to the stri, script.

182
00:11:21,179 --> 00:11:25,810
And just to be sure that we're not
violating any assumptions

183
00:11:25,810 --> 00:11:29,020
here because you might look at those
correlations and say, well

184
00:11:29,020 --> 00:11:31,580
that's weird why do we have, you know, no,
there's no

185
00:11:31,580 --> 00:11:34,890
correlation between age and physical
endurance, that doesn't make much sense.

186
00:11:36,100 --> 00:11:40,590
let's just look at our our distributions.

187
00:11:43,670 --> 00:11:48,000
So we'll just run some histograms and look
at the distributions.

188
00:11:48,000 --> 00:11:51,650
So here's age we have a, a large range
from

189
00:11:51,650 --> 00:11:54,930
like early 20s all the way up to around
80.

190
00:11:54,930 --> 00:11:58,250
These two, there's two people up here
right

191
00:11:58,250 --> 00:12:02,196
around 80, who, they're, they're almost
like outliers.

192
00:12:02,196 --> 00:12:05,440
We might want to consider dropping them
out of the sample

193
00:12:05,440 --> 00:12:09,030
but they're not so extreme that I'd, that
I'll drop them out.

194
00:12:09,030 --> 00:12:12,730
And they're not going to really affect
the, the outcome too much.

195
00:12:13,920 --> 00:12:18,945
active years looks a little bit positively
skewed, right, which

196
00:12:18,945 --> 00:12:22,550
is not, not unusual for that kind of a
measure.

197
00:12:22,550 --> 00:12:26,060
Then the endurance looks like a really
nice normal distribution.

198
00:12:26,060 --> 00:12:29,370
So there's nothing too unusual about these
distributions, they look

199
00:12:29,370 --> 00:12:32,240
pretty normal, we've got a little bit of a
positive skew.

200
00:12:32,240 --> 00:12:33,470
Maybe a couple of,

201
00:12:34,790 --> 00:12:36,350
a couple of data points that are close

202
00:12:36,350 --> 00:12:39,620
to being outliers here but nothing too
extreme.

203
00:12:39,620 --> 00:12:43,470
so let's go ahead and run the regression
analyses, that's, those look good enough.

204
00:12:44,940 --> 00:12:53,260
so let's run first, let's run a regression
analysis predicting endurance from age.

205
00:12:53,260 --> 00:12:56,180
Remember there's no correlation between
endurance and

206
00:12:56,180 --> 00:12:59,950
age, so we shouldn't get a significant
regression

207
00:12:59,950 --> 00:13:03,596
coefficient, but let's run the model
anyway, just to be sure.

208
00:13:03,596 --> 00:13:06,610
So, I'm going to call this Model One.

209
00:13:06,610 --> 00:13:09,650
I'm using the function lm, that's for
linear model, because

210
00:13:09,650 --> 00:13:13,240
right now we're assuming linear
relationship between invariance and age.

211
00:13:13,240 --> 00:13:15,810
And we can check that in scatter plot.

212
00:13:15,810 --> 00:13:19,730
I'm using the function summary, just to
give me the output that's associated with

213
00:13:19,730 --> 00:13:22,410
that model, that'll give us the regression

214
00:13:22,410 --> 00:13:26,090
constant and the regression coefficient
for age

215
00:13:26,090 --> 00:13:27,930
when predicting endurance.

216
00:13:27,930 --> 00:13:29,100
And you'll see it'll give us a bunch of

217
00:13:29,100 --> 00:13:32,790
other things, like model r squared, and so
on.

218
00:13:32,790 --> 00:13:34,390
So let me just run that.

219
00:13:39,450 --> 00:13:45,500
So here's the output, I ran this Model One
and here's summary Model One.

220
00:13:45,500 --> 00:13:47,380
it gives us a range of residuals, which
I'll

221
00:13:47,380 --> 00:13:49,500
actually show you on a plot in a moment.

222
00:13:49,500 --> 00:13:52,510
But this is the most important piece of
the output right

223
00:13:52,510 --> 00:13:57,500
here and what you'll typically look to
when you do regression

224
00:13:57,500 --> 00:14:01,080
analysis, which you'll do for the next
assignment and the next

225
00:14:01,080 --> 00:14:04,650
couple weeks when we do multiple
regression when we put in more

226
00:14:04,650 --> 00:14:08,375
than one predictor.
it gives us our estimates, these are the

227
00:14:08,375 --> 00:14:13,140
coefficients.
So this right here is the intercept, or in

228
00:14:13,140 --> 00:14:19,440
my lecture notes this was b sub zero in
the regression equation, it's just

229
00:14:19,440 --> 00:14:24,824
the predicted score on y when x is zero.
So, if someone had

230
00:14:24,824 --> 00:14:30,156
an age of zero we would predict they would
score

231
00:14:30,156 --> 00:14:34,920
30.8 on this arbitrary scale.

232
00:14:36,310 --> 00:14:40,110
Again, age doesn't really correlate with
endurance

233
00:14:40,110 --> 00:14:44,200
so 30 should be around the average,

234
00:14:44,200 --> 00:14:47,450
I can't remember what the average was, but
it should be somewhere near there.

235
00:14:48,510 --> 00:14:50,850
and we see is the estimate for

236
00:14:50,850 --> 00:14:56,990
the regression coefficient for age
predicting endurance

237
00:14:56,990 --> 00:14:58,642
is negative 0.08.

238
00:14:58,642 --> 00:15:01,290
it's standard error is 0.07 that's just
how

239
00:15:01,290 --> 00:15:04,590
much of a relationship should we expect
just due

240
00:15:04,590 --> 00:15:07,870
to chance, so it's about the same as, as,

241
00:15:07,870 --> 00:15:12,350
you know, the actual coefficient, so it's
not significant.

242
00:15:12,350 --> 00:15:17,020
Another thing to look for is this multiple
r squared.

243
00:15:17,020 --> 00:15:21,916
So, in this case, it's just, literally, r
squared, the correlation squared.

244
00:15:21,916 --> 00:15:26,840
but when we get into multiple regression,
you'll see that this is the, this is the

245
00:15:26,840 --> 00:15:34,030
proportion of variance in y explained by x
or x's, all the predictors.

246
00:15:34,030 --> 00:15:38,800
So, it's the proportion of variance of, in
y explained by the model.

247
00:15:38,800 --> 00:15:42,040
So, you'll see that it's 0.01, only 1%

248
00:15:42,040 --> 00:15:46,220
of the variance in endurance is explained
by age.

249
00:15:46,220 --> 00:15:47,200
They're just not related

250
00:15:47,200 --> 00:15:47,910
in this sample.

251
00:15:49,960 --> 00:15:52,440
Let's look at another example.

252
00:15:52,440 --> 00:15:54,610
let me just do the scatter plot to show

253
00:15:54,610 --> 00:15:58,880
you what it looks like, so there's the
scatter plot.

254
00:16:01,424 --> 00:16:05,710
y or, on the y axis I have endurance, on
the x axis I have age.

255
00:16:05,710 --> 00:16:07,440
And you see it's almost a flat line, it's
just

256
00:16:07,440 --> 00:16:13,460
a very slight negative slope, because the
correlation was negative 0.08.

257
00:16:13,460 --> 00:16:15,530
but basically no relationship going on
there.

258
00:16:17,450 --> 00:16:19,250
Now, let's look at two variables that

259
00:16:19,250 --> 00:16:22,360
are correlated, so active years, predicted
endurance.

260
00:16:22,360 --> 00:16:26,530
So let's, in model two, let's again use
that lm

261
00:16:26,530 --> 00:16:32,990
function but now let's look at a variable
that predicts endurance.

262
00:16:32,990 --> 00:16:36,410
So now when we look at the summary, now
let me go down

263
00:16:36,410 --> 00:16:38,800
to the coefficients, this is really what
we want to look at, right?

264
00:16:40,100 --> 00:16:44,690
now you'll see that the predicted score on
y

265
00:16:44,690 --> 00:16:47,240
when x is zero, now is much lower, right?

266
00:16:47,240 --> 00:16:51,850
Because if you have not, if you have zero
active years then

267
00:16:51,850 --> 00:16:53,340
you're going to, I'm going to predict that
you

268
00:16:53,340 --> 00:16:59,060
have a much lower score on the endurance
scale.

269
00:16:59,060 --> 00:17:03,200
And here is the unstandardized regression
coefficient, okay.

270
00:17:03,200 --> 00:17:06,000
Remember, this is unstandardized, so you
can't really

271
00:17:06,000 --> 00:17:08,170
think of this in terms of like
correlation.

272
00:17:09,600 --> 00:17:13,700
this is just the, for every one unit
change in

273
00:17:13,700 --> 00:17:16,920
active years, so for every one more active
year, it's the

274
00:17:16,920 --> 00:17:22,180
predicted change in the endurance scale,
so, it's almost a one to one.

275
00:17:22,180 --> 00:17:28,824
So, for every one more active year I'm
going to put a 0.75 not quite one.

276
00:17:28,824 --> 00:17:33,120
one more, one point higher on that
endurance scale.

277
00:17:33,120 --> 00:17:35,920
And is that a statistically significant
relationship?

278
00:17:35,920 --> 00:17:38,310
Well, yes because this t value,

279
00:17:38,310 --> 00:17:41,325
which is just the unstandardized
regression coefficient,

280
00:17:41,325 --> 00:17:49,790
0.7552 divided by the standard error,
0.1553, that's the t value

281
00:17:49,790 --> 00:17:55,410
and it corresponds to a p value of like
0.000002,

282
00:17:55,410 --> 00:17:56,894
[LAUGH]

283
00:17:56,894 --> 00:17:58,390
so really, really low.

284
00:17:59,560 --> 00:18:03,470
so, yes I would reject the null hypothesis
that there's no relationship.

285
00:18:05,390 --> 00:18:07,980
and we could conclude that there's a
statistically significant

286
00:18:07,980 --> 00:18:11,820
relationship between active years and
endurance, not very surprising.

287
00:18:11,820 --> 00:18:15,530
The other thing I want to look at here is
the multiple r squared.

288
00:18:15,530 --> 00:18:18,510
You see now we're explaining about 11% of

289
00:18:18,510 --> 00:18:21,870
the variance and endurance just from
active years.

290
00:18:23,410 --> 00:18:27,740
Okay, let's go back to the script.
we can visualize that in a plot.

291
00:18:31,330 --> 00:18:36,660
And here’s the scatter plot.
Looking at endurance as

292
00:18:36,660 --> 00:18:41,370
a function of active years and you see
there's this nice, positive slope, okay.

293
00:18:45,660 --> 00:18:46,810
Okay.

294
00:18:46,810 --> 00:18:52,060
Now in model three I'm actually going to
do technically a multiple regression.

295
00:18:52,060 --> 00:18:55,270
I know we haven't really gotten into the
heart of multiple regression

296
00:18:55,270 --> 00:18:58,740
yet but just to show you why this, this
example is interesting

297
00:18:58,740 --> 00:19:03,930
and, and what can happen with multiple
regression, let's put both age and

298
00:19:03,930 --> 00:19:10,210
active years in the regression equation
together and predict endurance from that.

299
00:19:10,210 --> 00:19:10,690
And, you'll see

300
00:19:10,690 --> 00:19:11,660
this is pretty interesting.

301
00:19:14,530 --> 00:19:20,440
So now let me again, direct you to the
coefficients table.

302
00:19:21,990 --> 00:19:27,072
Now if we look at age we get relationship
of negative,

303
00:19:27,072 --> 00:19:31,988
a slope of negative 0.222 or 0.223.

304
00:19:31,988 --> 00:19:34,530
And but notice now there is now the t

305
00:19:34,530 --> 00:19:38,280
value is negative three and the p value is
0.002.

306
00:19:38,280 --> 00:19:40,430
So now

307
00:19:40,430 --> 00:19:43,026
again, using a cut off of 0.05 and, and

308
00:19:43,026 --> 00:19:46,530
we'll talk next week when we talk about
central limit

309
00:19:46,530 --> 00:19:50,142
theorem and sampling distributions, why we
use the cut-off

310
00:19:50,142 --> 00:19:54,120
of 0.05 but it's, it's a very low p value.

311
00:19:54,120 --> 00:19:59,530
So the probability of getting this slope
and this t value, the probability of

312
00:19:59,530 --> 00:20:01,921
obtaining those values given the
assumption that

313
00:20:01,921 --> 00:20:05,380
there's no relat, relationship between age
and endurance,

314
00:20:05,380 --> 00:20:06,990
again that's the null hypothesis.

315
00:20:06,990 --> 00:20:09,610
The probability of that happening, given
the assumption of the

316
00:20:09,610 --> 00:20:12,920
null, is really really low, so I reject
the null.

317
00:20:12,920 --> 00:20:14,640
And now we can claim that there

318
00:20:14,640 --> 00:20:17,640
is a statistically significant
relationship between age and

319
00:20:17,640 --> 00:20:20,720
endurance and it's because we've taken
into account

320
00:20:20,720 --> 00:20:24,340
active years which is also a significant
predictor.

321
00:20:24,340 --> 00:20:28,120
So now, both of them are significantly
predicting endurance.

322
00:20:28,120 --> 00:20:30,940
And if we go down to the model, r squared,
you can see

323
00:20:30,940 --> 00:20:33,850
we're doing a lot better now by putting in
age and the active

324
00:20:33,850 --> 00:20:39,060
years together, we're accounting for about
15% of the variants in the outcome.

325
00:20:39,060 --> 00:20:43,890
Whereas, if we go back up to our old
output, if we just used active years,

326
00:20:43,890 --> 00:20:48,260
and we didn't put in age, we were only
accounting for about 11% of the variance.

327
00:20:48,260 --> 00:20:53,650
So, the model gets better by putting in
both age and active years together.

328
00:20:53,650 --> 00:20:56,200
And that's the power of multiple
regression, which we're going to talk

329
00:20:56,200 --> 00:20:58,665
a lot about in the next next

330
00:20:58,665 --> 00:21:00,439
two weeks we'll be talking about multiple
regression.

331
00:21:02,190 --> 00:21:03,890
Okay, so let's go back to the script.

332
00:21:05,780 --> 00:21:10,930
we can't visualize that in one scatter
plot if we had both age and physical

333
00:21:10,930 --> 00:21:16,070
endurance, so what we're going to do to
visualize model three in just

334
00:21:16,070 --> 00:21:21,230
one scatter plot, and I did this in the
lecture, we could save the

335
00:21:21,230 --> 00:21:22,970
predicted scores.

336
00:21:22,970 --> 00:21:28,780
Because another way to think of that, that
model r squared is it's the correlation

337
00:21:28,780 --> 00:21:34,630
between the predicted scores and the
actual observed scores on y squared.

338
00:21:34,630 --> 00:21:39,880
So a way to do that in R, and this is a
really handy function,

339
00:21:39,880 --> 00:21:45,330
the fitted function, that will give me the
predicted scores from the model.

340
00:21:45,330 --> 00:21:46,410
So I'm going to create

341
00:21:46,410 --> 00:21:50,176
a new variable called predicted in my data
frame PE

342
00:21:50,176 --> 00:21:54,660
and I'm going to just put the predicted
scores there.

343
00:21:55,830 --> 00:22:00,800
Then, I'll plot the predicted scores
against endurance.

344
00:22:03,160 --> 00:22:06,430
And now you see the slope is, it's
probably

345
00:22:06,430 --> 00:22:08,220
hard to tell, I should have put them maybe
right

346
00:22:08,220 --> 00:22:10,280
next to each other, this slope is even a

347
00:22:10,280 --> 00:22:15,800
little bit stronger than the slope in the
previous plot.

348
00:22:15,800 --> 00:22:20,016
just using active years to predict
endurance, right.

349
00:22:20,016 --> 00:22:23,190
Because the r squared was a little higher,
so this is just

350
00:22:23,190 --> 00:22:28,250
the predicted scores from model three
predicting endurance, and that's a little

351
00:22:28,250 --> 00:22:30,880
bit better than just active years by
itself.

352
00:22:30,880 --> 00:22:36,090
So it's a way to visualize in one scatter
plot this model three relationship.

353
00:22:37,790 --> 00:22:40,510
Okay, we can also save the residuals,
which is a

354
00:22:40,510 --> 00:22:46,426
very important lesson and something we'll
use a lot going forward.

355
00:22:46,426 --> 00:22:52,150
So, we want to, if we save the residuals
into a variable just called e, for error,

356
00:22:53,220 --> 00:23:00,110
then I could visualize the residuals.
So, we should see that I have a normal

357
00:23:00,110 --> 00:23:07,620
distribution of residuals, centered at
zero and sure enough that's what we get.

358
00:23:07,620 --> 00:23:09,130
So if I just do a histogram of

359
00:23:09,130 --> 00:23:14,080
the residuals they're centered right
around zero because some

360
00:23:14,080 --> 00:23:18,510
of my prediction errors are, are too high,
and some of them are too low, all right.

361
00:23:18,510 --> 00:23:23,080
And this, this satisfies the assumption of
homoscedasticity, right.

362
00:23:23,080 --> 00:23:24,530
The prediction errors are just sort of

363
00:23:24,530 --> 00:23:30,040
randomly fluctuating across that, that x
variable

364
00:23:30,040 --> 00:23:32,260
and some are negative, some are positive

365
00:23:32,260 --> 00:23:34,390
and there's a normal distribution around
zero.

366
00:23:34,390 --> 00:23:36,934
So that's nice to see.

367
00:23:36,934 --> 00:23:38,668
if we save our residuals and plot it in
the

368
00:23:38,668 --> 00:23:41,010
histogram, that's the sort of thing we
want to see.

369
00:23:42,220 --> 00:23:43,680
I could then look

370
00:23:43,680 --> 00:23:49,510
at the relationship between the actual,
the predicted scores

371
00:23:49,510 --> 00:23:54,520
and the residuals and of course, those are
going to be orthogonal to one another.

372
00:23:56,710 --> 00:24:00,830
And sure enough, if I look at the
residuals in relationship to the predicted

373
00:24:00,830 --> 00:24:06,310
scores then there's no correlation there,
and that's, that

374
00:24:06,310 --> 00:24:11,790
should be obvious.
Okay, so I'm almost done with this

375
00:24:11,790 --> 00:24:17,270
lab but I just want to show you how to get
standardized regression coefficients.

376
00:24:17,270 --> 00:24:22,430
It's real simple we're just going to run
the same exact models that we did up

377
00:24:22,430 --> 00:24:26,170
above, except we're going to put this word
scale, not

378
00:24:26,170 --> 00:24:30,770
just word but function scale, around each
one of our variables.

379
00:24:30,770 --> 00:24:32,950
So if I just put scale in front of all the

380
00:24:32,950 --> 00:24:35,670
variables in all of these models

381
00:24:35,670 --> 00:24:40,020
then we'll get standardized regression
coefficients.

382
00:24:40,020 --> 00:24:43,940
Just to remind you that the standardized
regression

383
00:24:43,940 --> 00:24:47,520
coefficients in a simple regression, and
remember it's

384
00:24:47,520 --> 00:24:50,000
only in a simple regression, the
standardized

385
00:24:50,000 --> 00:24:53,330
regression coefficients will equal the
correlation coefficient.

386
00:24:53,330 --> 00:24:56,030
So just to remind us what the correlation

387
00:24:56,030 --> 00:24:59,100
coefficients are I'm going to run the
correlations again.

388
00:24:59,100 --> 00:25:01,720
And then I'll run these two simple
regressions

389
00:25:01,720 --> 00:25:04,740
to show you that those should be
equivalent.

390
00:25:09,130 --> 00:25:12,600
So, this gave me a lot of outputs.
Let me go up.

391
00:25:16,084 --> 00:25:16,646
so

392
00:25:16,646 --> 00:25:18,051
[COUGH]

393
00:25:18,051 --> 00:25:26,400
there we are.
here are the correlation coefficients, I

394
00:25:26,400 --> 00:25:31,370
just got that by running the core function
again and I rounded it to make it clean.

395
00:25:31,370 --> 00:25:37,145
so remember they're about 0.33 for, for
active years predicting endurance

396
00:25:37,145 --> 00:25:43,060
but negative 0.08 for endurance, or sorry,
for age predicting endurance.

397
00:25:43,060 --> 00:25:47,660
So, in this first model we, we use the
function scale to get standardized

398
00:25:47,660 --> 00:25:52,570
coefficients, age predicting endurance,
what is the

399
00:25:53,640 --> 00:25:58,876
progression coefficient?
Well, it's negative 0.08, exactly

400
00:25:58,876 --> 00:26:03,624
the correlation coefficient, okay.
Then if we

401
00:26:03,624 --> 00:26:08,554
go down and look at the coefficient

402
00:26:08,554 --> 00:26:15,594
for active years it's 0.326 or 0.33.

403
00:26:15,594 --> 00:26:19,158
Okay, so it's exactly the same as the
correlation coefficient

404
00:26:19,158 --> 00:26:23,630
when we get the standardized regression
coefficient in a simple regression.

405
00:26:24,630 --> 00:26:29,510
Now that's not going to be true when we go
to multiple regression.

406
00:26:29,510 --> 00:26:33,890
So once we add in another predictor,
remember those

407
00:26:33,890 --> 00:26:38,610
coefficients can change and it, it changes
a great deal in this example, that's

408
00:26:38,610 --> 00:26:42,750
why I use this example, it's sort of a
nice one, those coefficients can change.

409
00:26:42,750 --> 00:26:46,710
So now even with the standardized
regression coefficients,

410
00:26:46,710 --> 00:26:49,940
they're not going to equal the correlation
coefficients anymore.

411
00:26:49,940 --> 00:26:50,680
So I run that, and

412
00:26:52,970 --> 00:26:58,775
now you see I have a, a standardized
regression coefficient for age of negative

413
00:26:58,775 --> 00:27:05,600
0.22 and for active years it went up a
little bit which is sort of unusual.

414
00:27:05,600 --> 00:27:09,030
This is a unique example that's why I used
this.

415
00:27:09,030 --> 00:27:14,830
it went up to almost 0.4 so it's now in
multiple regression.

416
00:27:14,830 --> 00:27:17,980
The standardized regression coefficients,
they're still going to range from

417
00:27:17,980 --> 00:27:21,270
like negative one to positive one but
they're not

418
00:27:21,270 --> 00:27:25,012
going to be equal to the Pearson
product-moment correlation.

419
00:27:25,012 --> 00:27:27,880
So it's really important to know that in
multiple regression, the

420
00:27:27,880 --> 00:27:29,660
standardized regression coefficients will
not

421
00:27:29,660 --> 00:27:32,400
be equal to the correlation coefficient.

422
00:27:32,400 --> 00:27:34,080
In simple regression, which is one

423
00:27:34,080 --> 00:27:36,544
predictor in the equation, yes, the
standardized

424
00:27:36,544 --> 00:27:39,008
regression coefficient will equal the
correlation

425
00:27:39,008 --> 00:27:41,509
coefficient but not here in multiple
regression.

426
00:27:41,509 --> 00:27:43,043
And that's what we are going to

427
00:27:43,043 --> 00:27:47,600
do in the next couple of weeks we're going
to do more of these multiple regressions.

428
00:27:47,600 --> 00:27:49,677
Just one last thing I want to point out

429
00:27:49,677 --> 00:27:52,223
here, is notice that the r squared is
exactly

430
00:27:52,223 --> 00:27:55,439
the same for the standard, the
standardized solution as

431
00:27:55,439 --> 00:27:59,062
it is for the unstandardized and hopefully
that makes sense.

432
00:27:59,062 --> 00:28:01,930
All we're doing with the standardized
solution is we're just changing

433
00:28:01,930 --> 00:28:06,360
the scale of the variables, so the
relationships remain exactly the same.

434
00:28:06,360 --> 00:28:08,070
If you wanted to visualize that you could
just

435
00:28:08,070 --> 00:28:09,470
plot it.

436
00:28:09,470 --> 00:28:14,280
but you can see the, the code, the p
values, the t values for these

437
00:28:14,280 --> 00:28:19,710
coefficients are exactly the same as
before and this multiple r squared.

438
00:28:19,710 --> 00:28:21,730
The proportion of variance explained in y
is

439
00:28:21,730 --> 00:28:24,680
exactly the same as when we did it
unstandardized.

440
00:28:24,680 --> 00:28:27,380
Okay so that's it for lab four.

441
00:28:27,380 --> 00:28:29,670
That's everything you'll need for the next
assignment, good

442
00:28:29,670 --> 00:28:31,400
luck on that and I'll talk to you next
week.

