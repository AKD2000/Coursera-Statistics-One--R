
1
00:00:03,270 --> 00:00:05,540
Hi, and welcome back to Statistics One.

2
00:00:05,540 --> 00:00:07,830
We're up to Lecture 7 now, and the

3
00:00:07,830 --> 00:00:12,050
topic of Lecture 7 is Introduction to
Regression.

4
00:00:12,050 --> 00:00:16,530
This is a pretty critical lecture in that
we're going to make a sort of

5
00:00:16,530 --> 00:00:19,790
a transition point, away from correlation
and

6
00:00:19,790 --> 00:00:25,610
descriptive statistics into regression,
prediction and inferential statistics.

7
00:00:25,610 --> 00:00:27,400
So this is a really crucial lecture.

8
00:00:29,780 --> 00:00:33,180
This lecture is divided into three
segments.

9
00:00:33,180 --> 00:00:38,240
So in the first segment, I'll just give
you an overview of regression.

10
00:00:38,240 --> 00:00:40,830
just what does it do, what is it used for?

11
00:00:40,830 --> 00:00:41,678
Just the basics.

12
00:00:41,678 --> 00:00:44,590
In the second segment, we'll do some math,

13
00:00:44,590 --> 00:00:48,390
we'll talk about the calculation of the
regression coefficients.

14
00:00:48,390 --> 00:00:50,290
And then in the third segment we'll talk

15
00:00:50,290 --> 00:00:54,900
about assumptions underlying a linear
regression analysis, which is

16
00:00:54,900 --> 00:00:56,880
what we're starting with here.

17
00:00:56,880 --> 00:01:00,710
So let's dive into just the basics of
regression.

18
00:01:03,030 --> 00:01:07,570
The most important concepts and topics to
take away from this segment are

19
00:01:07,570 --> 00:01:09,800
just to understand the simple difference
or

20
00:01:09,800 --> 00:01:13,910
distinction between simple regression and
multiple regression.

21
00:01:13,910 --> 00:01:18,030
And then understand the components of the
regression equation.

22
00:01:18,030 --> 00:01:20,070
And also understand what it means to have

23
00:01:20,070 --> 00:01:23,340
a regression model and how to evaluate a
model.

24
00:01:26,030 --> 00:01:30,930
So, last week we spent a lot of time
talking about correlation and one of

25
00:01:30,930 --> 00:01:34,210
the things I asked and kept repeatedly
asking

26
00:01:34,210 --> 00:01:36,830
is, what is, what are correlations good
for?

27
00:01:36,830 --> 00:01:39,070
Well, correlations are good for
prediction.

28
00:01:39,070 --> 00:01:42,600
That is, if I know that two variables are
highly

29
00:01:42,600 --> 00:01:45,790
correlated then I can use one to predict
the other.

30
00:01:45,790 --> 00:01:50,000
That's exactly what regression analysis is
designed to do.

31
00:01:50,000 --> 00:01:52,160
So now we'll formally

32
00:01:52,160 --> 00:01:55,760
specify one variable as an outcome
variable, and

33
00:01:55,760 --> 00:02:00,240
another variable or a set of variables as
predictors.

34
00:02:00,240 --> 00:02:03,160
And we'll create a regression equation,
regression

35
00:02:03,160 --> 00:02:07,650
model to predict scores on that outcome
variable.

36
00:02:07,650 --> 00:02:12,920
So that's regression in a nutshell.
And very simply, the distinction

37
00:02:12,920 --> 00:02:17,670
between simple regression and multiple
regression, is simple regression only

38
00:02:17,670 --> 00:02:20,340
involves one predictor variable.

39
00:02:20,340 --> 00:02:25,540
Whereas multiple regression, we can have
as many predictor variables as we want.

40
00:02:25,540 --> 00:02:29,220
So, most of the time, we'll be doing
multiple regression, but

41
00:02:29,220 --> 00:02:34,440
for this first intro segment, I'll mainly
stick with simple regression.

42
00:02:34,440 --> 00:02:36,740
You'll see it's so easy that I'll just,
I'll have to

43
00:02:36,740 --> 00:02:40,450
sneak in a little bit of multiple
regression, just one example.

44
00:02:40,450 --> 00:02:43,370
just to show you the power of multiple
regression.

45
00:02:46,160 --> 00:02:49,330
The example I'm going to use for this
segment is

46
00:02:49,330 --> 00:02:51,450
an example that you should be used to by
now.

47
00:02:51,450 --> 00:02:53,600
It's the IMPACT data set.

48
00:02:53,600 --> 00:02:55,360
We used it way back in Lab 2.

49
00:02:55,360 --> 00:02:58,230
We actually used it in Lab 3 as well.

50
00:02:58,230 --> 00:03:03,070
but if you're only following the lectures,
if you're not watching the labs then you

51
00:03:03,070 --> 00:03:08,200
can go to this website and get a feel for
what the IMPACT assessment tool does.

52
00:03:08,200 --> 00:03:11,980
It's an online assessment tool designed to

53
00:03:11,980 --> 00:03:15,850
investigate the effects of sports-related
concussion.

54
00:03:15,850 --> 00:03:21,290
And again, we looked at these data in, in
Labs 2 and 3 actually.

55
00:03:21,290 --> 00:03:25,100
and we're going to look at them again here
in this segment in, on regression.

56
00:03:27,500 --> 00:03:33,470
So if you recall, IMPACT provides data on
six measures or six variables.

57
00:03:33,470 --> 00:03:38,490
It assesses your cognitive performance.
And also asks athletes

58
00:03:38,490 --> 00:03:43,310
about symptoms that they might be
experiencing, perhaps after

59
00:03:43,310 --> 00:03:48,270
suffering a really bad injury while

60
00:03:48,270 --> 00:03:53,006
playing a sport or while practicing.

61
00:03:53,006 --> 00:03:56,844
So the main measures are verbal memory,
visual memory,

62
00:03:56,844 --> 00:04:01,164
visual motor speed, reaction time, impulse
control, and symptom score.

63
00:04:01,164 --> 00:04:07,610
Symptom score is just a checklist really
of how the athlete is feeling.

64
00:04:07,610 --> 00:04:11,930
So that's something that most athletic
departments, even high school athletic

65
00:04:11,930 --> 00:04:18,470
departments, will have at their disposal.
All these other cognitive online

66
00:04:18,470 --> 00:04:24,484
measures are, are more modern and that's
where IMPACT is designed to provide.

67
00:04:24,484 --> 00:04:27,700
so what we're going to do in this segment
is see

68
00:04:27,700 --> 00:04:32,158
if we can predict symptom score from these
newer measures.

69
00:04:32,158 --> 00:04:38,290
So, if you go back to the Labs, and
particularly

70
00:04:38,290 --> 00:04:43,570
Lab 3, we saw this correlation matrix.
So remember,

71
00:04:43,570 --> 00:04:47,240
the topic of last week was correlation and
measurement.

72
00:04:47,240 --> 00:04:51,274
And in the Lab, we talked about
correlation matrices.

73
00:04:51,274 --> 00:04:54,060
so you, you've seen this before but let's
review.

74
00:04:55,130 --> 00:04:57,550
these are the correlations among the six

75
00:04:57,550 --> 00:05:03,850
main measures before athletes incurred any
injury.

76
00:05:03,850 --> 00:05:06,230
So, you see some things that make sense,

77
00:05:06,230 --> 00:05:09,080
so for example, if we look at the
correlation

78
00:05:09,080 --> 00:05:14,690
between verbal memory and visual memory,
that's about 0.442, it's positive,

79
00:05:14,690 --> 00:05:19,700
so that's good, that makes sense.
their two memory measures.

80
00:05:20,970 --> 00:05:25,670
we also see a correlation of negative 0.5

81
00:05:25,670 --> 00:05:30,166
between visual motor speed and overall
reaction time.

82
00:05:30,166 --> 00:05:35,290
The reason it's negative is because higher
scores on visual motor speed

83
00:05:35,290 --> 00:05:39,250
meant better performance whereas lower
scores, faster

84
00:05:39,250 --> 00:05:43,400
reaction times, and overall reaction time
meant better performance.

85
00:05:43,400 --> 00:05:47,720
But they're both speed measures, so the
fact that they're correlated is good.

86
00:05:47,720 --> 00:05:55,270
But remember, the other thing to notice in
this pre-injury data set is symptom score

87
00:05:55,270 --> 00:06:00,450
doesn't really correlate with anything.
And that's because the athletes aren't

88
00:06:00,450 --> 00:06:03,290
really experiencing any symptoms.
They're healthy.

89
00:06:03,290 --> 00:06:06,850
No one's suffered an injury yet.

90
00:06:06,850 --> 00:06:14,040
And we demonstrated this graphically in
our fancy scatter plot matrix

91
00:06:14,040 --> 00:06:20,090
organized by color so the brighter colors
indicate stronger correlations.

92
00:06:20,090 --> 00:06:25,940
So you see, here's the correlation between
verbal memory and visual memory

93
00:06:25,940 --> 00:06:27,909
that I referred to.

94
00:06:27,909 --> 00:06:34,535
but again, the other thing to notice here
is where is symptom score on this graph?

95
00:06:34,535 --> 00:06:39,665
It's, it's in the periphery, and most of
its correlations are colored blue.

96
00:06:39,665 --> 00:06:45,059
That's because most people are at the
floor, or they don't show any

97
00:06:45,059 --> 00:06:51,011
symptom score, so if there's no variance
in symptoms, then we can't have

98
00:06:51,011 --> 00:06:56,497
co-variance in symptoms.
so symptoms isn't correlating any, with

99
00:06:56,497 --> 00:07:04,060
anything before an injury.
So let's look at the data post-injury.

100
00:07:04,060 --> 00:07:07,670
So now, I'm just looking at athletes after
suffering a

101
00:07:07,670 --> 00:07:12,000
concussion and now you start to see some
things change.

102
00:07:12,000 --> 00:07:16,200
Particularly in this bottom row with
respect to symptom score.

103
00:07:16,200 --> 00:07:19,820
So now, symptom score is showing some
action.

104
00:07:19,820 --> 00:07:25,830
And in particular, this correlation here
with impulse control, of 0.4.

105
00:07:25,830 --> 00:07:30,020
So, this new measure of impulse control
that was

106
00:07:30,020 --> 00:07:34,615
designed by the developers of this online
website IMPACT,

107
00:07:34,615 --> 00:07:38,590
their, their measure of impulse control is
correlating with

108
00:07:38,590 --> 00:07:42,030
symptom score, which is just a survey
checklist at 0.4.

109
00:07:42,030 --> 00:07:44,300
So it's a pretty impressive post-injury.

110
00:07:44,300 --> 00:07:46,990
What this means is their impulse control
measure

111
00:07:46,990 --> 00:07:50,830
is pretty diagnostic of an injury, most
likely.

112
00:07:50,830 --> 00:07:55,060
So we could use that to predict symptom
score, and that's what we'll do.

113
00:07:56,260 --> 00:08:00,420
again we could demonstrate those
correlations graphically and in

114
00:08:00,420 --> 00:08:05,450
a scatter plot matrix colored by magnitude
of correlation.

115
00:08:05,450 --> 00:08:07,680
so now you see here

116
00:08:07,680 --> 00:08:11,510
symptom score, it's no longer out in the
periphery.

117
00:08:11,510 --> 00:08:14,110
All color blue not correlating with
anything.

118
00:08:14,110 --> 00:08:17,860
It's correlated pretty well with impulse
control.

119
00:08:17,860 --> 00:08:22,240
It's also correlated with verbal memory.

120
00:08:22,240 --> 00:08:25,630
those are the two I'm going to enter into
the regression equation in this example.

121
00:08:28,290 --> 00:08:32,760
So for this example and this is just for
illustrative purposes.

122
00:08:32,760 --> 00:08:36,180
There's, you could, you could flip things
around and predict,

123
00:08:36,180 --> 00:08:38,490
you know, impulse control from symptom
Score and so on.

124
00:08:38,490 --> 00:08:43,313
I'm just doing this as an example because
we're familiar with this data.

125
00:08:43,313 --> 00:08:46,153
but for this example let's put symptom
score in

126
00:08:46,153 --> 00:08:49,551
as the outcome variable, so it's going to
be variable Y.

127
00:08:49,551 --> 00:08:53,994
And then for the simple regression we'll
just put in one variable.

128
00:08:53,994 --> 00:08:55,771
That's going to be impulse control.

129
00:08:55,771 --> 00:08:58,444
And then, as I said, I want to show you a

130
00:08:58,444 --> 00:09:03,478
multiple regression so we'll put in
impulse control and verbal memory.

131
00:09:03,478 --> 00:09:08,960
But before we do that, let's take a closer
look at the actual regression equation.

132
00:09:08,960 --> 00:09:13,486
I'm going to show you, show you the
regression equation with two different

133
00:09:13,486 --> 00:09:19,220
forms of notation.
This first form notation I'm only

134
00:09:19,220 --> 00:09:24,560
presenting because I think some of you
might be familiar with it, from maybe a

135
00:09:24,560 --> 00:09:30,210
high school geometry class.
it's the formula for a line, right?

136
00:09:30,210 --> 00:09:37,920
It says that Y is a linear function of X,
m is just the intercept, b is the slope.

137
00:09:37,920 --> 00:09:40,270
So if you remember this from high school
geometry,

138
00:09:40,270 --> 00:09:43,510
the b, the slope is the rise over run.

139
00:09:43,510 --> 00:09:44,810
Remember that?

140
00:09:44,810 --> 00:09:48,279
That's all we're looking at here.
That's all a simple regression does.

141
00:09:50,040 --> 00:09:56,520
but I'm going to switch to this notation,
because this is more common in statistics,

142
00:09:56,520 --> 00:09:58,530
and it's a more general notation that

143
00:09:58,530 --> 00:10:02,460
allows us to move into multiple
regression.

144
00:10:02,460 --> 00:10:04,350
and you'll see this in textbooks and on

145
00:10:04,350 --> 00:10:09,590
websites if you're looking for other
information about statistics.

146
00:10:09,590 --> 00:10:14,380
So, we're going to use B for the
regression coefficients, and

147
00:10:14,380 --> 00:10:19,010
B subzero is the intercept.
And another name for that is the

148
00:10:19,010 --> 00:10:24,790
regression constant B sub 1 is just the
slope relating X1 to Y.

149
00:10:26,030 --> 00:10:29,520
Again it's the same formula.
It's just a formula for a line.

150
00:10:32,350 --> 00:10:37,480
One other thing, or one other component of
regression that I want to highlight now,

151
00:10:37,480 --> 00:10:43,810
is we can also look at the model, the
overall models, R squared.

152
00:10:43,810 --> 00:10:46,490
This tells us the proportion of variance
in

153
00:10:46,490 --> 00:10:50,120
the outcome measure that is explained by
the predictors.

154
00:10:51,430 --> 00:10:53,710
At first when we just do simple
regression, it's

155
00:10:53,710 --> 00:10:57,080
just going to be the correlation
coefficient, little r squared.

156
00:10:58,610 --> 00:11:00,870
but when we build bigger models with

157
00:11:00,870 --> 00:11:04,155
more, more predictors this will get more
interesting.

158
00:11:04,155 --> 00:11:08,190
So you just want to highlight it now, that
we'll be looking at this multiple

159
00:11:08,190 --> 00:11:12,560
correlation coefficient, and particularly
R squared, the percentage

160
00:11:12,560 --> 00:11:15,230
of variance in y explained by the model.

161
00:11:17,730 --> 00:11:20,290
So now let's go back to the example.

162
00:11:20,290 --> 00:11:23,400
again, I'm going to put in symptom score
as the outcome measure.

163
00:11:23,400 --> 00:11:30,440
Impulse control as the predictor and then
solve for the regression coefficients.

164
00:11:30,440 --> 00:11:33,545
And I am just going to do this is R using
the function lm.

165
00:11:33,545 --> 00:11:39,200
You'll get a chance to play with this
function a lot in Lab this week.

166
00:11:39,200 --> 00:11:40,810
Lm just stands for linear model.

167
00:11:43,420 --> 00:11:47,570
So here's the scatter plot relating
impulse control to symptom score.

168
00:11:47,570 --> 00:11:50,110
You see there's a positive relationship.

169
00:11:50,110 --> 00:11:51,180
Remember, if you look back at the

170
00:11:51,180 --> 00:11:53,520
correlation matrix, the correlation was
about 0.4.

171
00:11:53,520 --> 00:11:57,930
Yep, I made a note of it, 0.4.

172
00:11:57,930 --> 00:12:03,980
and here are the regression coefficients.
So the constant is 20.48.

173
00:12:03,980 --> 00:12:08,440
Again, that's just the intercept, that's
the predicted score on

174
00:12:08,440 --> 00:12:14,250
Y when X is zero.
So 20.48, that's right there.

175
00:12:14,250 --> 00:12:17,220
It's the predicted score on Y when X is
zero.

176
00:12:18,830 --> 00:12:24,820
And then the slope of this line is 1.43.
What that tells us is, with every

177
00:12:24,820 --> 00:12:30,630
one unit increase in X, there's a 1.43
increase in Y.

178
00:12:32,220 --> 00:12:33,310
This last part, again,

179
00:12:33,310 --> 00:12:35,800
has to do with the model R squared.

180
00:12:35,800 --> 00:12:40,440
Since this is just a simple regression,
all I do is just square little r.

181
00:12:40,440 --> 00:12:45,345
So, r was 0.4, r squared is 0.16, so
impulse

182
00:12:45,345 --> 00:12:50,830
control is explaining 16% of the variance
in symptoms.

183
00:12:53,320 --> 00:12:58,480
Now, I got all of those numbers from the
output that

184
00:12:58,480 --> 00:13:03,730
I that I, that I got from R when I ran
this lm function.

185
00:13:03,730 --> 00:13:09,460
And again, you'll have a chance to do this
in Lab but just notice at the top, I call

186
00:13:09,460 --> 00:13:14,550
this function lm with symptom as the
outcome, impulse control

187
00:13:14,550 --> 00:13:18,690
as the predictor, and then I asked for a
summary.

188
00:13:18,690 --> 00:13:22,910
There's a lot of information here and
we'll cover a lot this in Lab.

189
00:13:22,910 --> 00:13:27,980
And then a, some more of it next week when
we cover multiple regression in depth.

190
00:13:27,980 --> 00:13:32,920
I just want to point out here, this is
where the regression coefficients came

191
00:13:32,920 --> 00:13:38,360
from.
So there's that 20.48, and 1.43 and

192
00:13:38,360 --> 00:13:43,848
then down at the bottom, there's my 0.16
or 16% as

193
00:13:43,848 --> 00:13:45,070
R squared.

194
00:13:45,070 --> 00:13:46,760
But the other thing you'll notice, and I
want

195
00:13:46,760 --> 00:13:49,980
to highlight, and this is, this is where
I'm

196
00:13:49,980 --> 00:13:52,370
referring to this lecture as sort of a
transition

197
00:13:52,370 --> 00:13:56,640
lecture, is there's all this other stuff
over here.

198
00:13:56,640 --> 00:14:02,350
R gives us all this other stuff, these
t-values and p-values, because now

199
00:14:02,350 --> 00:14:07,960
when we're doing regression, we're most
likely engaging in inferential statistics.

200
00:14:07,960 --> 00:14:08,960
We're not really interested

201
00:14:08,960 --> 00:14:13,690
in just describing this sample, we want to
know if this sample,

202
00:14:13,690 --> 00:14:17,900
the results from this sample are going to
generalize to other samples.

203
00:14:17,900 --> 00:14:20,920
For example, if I'm a high school football
coach and

204
00:14:20,920 --> 00:14:24,185
I want to know, does this online
assessment tool work.

205
00:14:24,185 --> 00:14:29,545
I'm going to look at somebody else's data
and then just use it at my own school.

206
00:14:29,545 --> 00:14:34,170
I'm not really interested in the
descriptives in, in these data.

207
00:14:34,170 --> 00:14:35,470
I want to know if I can make an

208
00:14:35,470 --> 00:14:40,610
inference from these sample data to a more
general population.

209
00:14:40,610 --> 00:14:43,970
And we, when we engage in inferential
statistics, we're

210
00:14:43,970 --> 00:14:46,550
going to start looking at these p values
and

211
00:14:46,550 --> 00:14:49,070
making probability judgments, and I'm
going to have a

212
00:14:49,070 --> 00:14:52,948
lot to say about that in the next two
lectures.

213
00:14:52,948 --> 00:14:55,120
but I just wanted to highlight it for you
now.

214
00:14:57,910 --> 00:15:01,970
Okay, so as I said, we're going to build
regression models

215
00:15:01,970 --> 00:15:05,720
that are much more interesting than just
having one predictor.

216
00:15:05,720 --> 00:15:10,380
We'll typically have two, three, lots of
predictors in there, and

217
00:15:10,380 --> 00:15:14,270
we'll just keep adding in more predictors
until we get better models.

218
00:15:17,490 --> 00:15:20,100
So to produce better models we can add

219
00:15:20,100 --> 00:15:23,830
more predictors or we could just develop
better predictors.

220
00:15:23,830 --> 00:15:26,310
So remember the lecture on measurement, we
could come up

221
00:15:26,310 --> 00:15:32,390
with more reliable measures or more valid
measures of our construct.

222
00:15:32,390 --> 00:15:35,200
So it doesn't always have to be just
adding in more predictors.

223
00:15:37,510 --> 00:15:40,550
But to see how this works, let's just do a
very quick example.

224
00:15:41,870 --> 00:15:43,630
I know this segment's getting a little
long,

225
00:15:43,630 --> 00:15:46,200
so let's just zip through this second
example.

226
00:15:46,200 --> 00:15:51,610
I'm just going to add in verbal memory as
a second predictor into this regression.

227
00:15:51,610 --> 00:15:56,690
Again, you can just use the function lm
and R, which you'll do in Lab this week.

228
00:15:58,810 --> 00:16:00,250
Here are the results.

229
00:16:00,250 --> 00:16:03,730
On the left is the entire R output, on

230
00:16:03,730 --> 00:16:07,280
the right I've summarized everything with
the regression equation.

231
00:16:07,280 --> 00:16:10,420
Again, I just took the regression
coefficients

232
00:16:10,420 --> 00:16:12,730
from this column and the output in R.

233
00:16:13,970 --> 00:16:19,490
And I just took the R squared from the
bottom here, it's 0.2167.

234
00:16:19,490 --> 00:16:23,970
I rounded up to about 22%.
So by adding in verbal memory

235
00:16:23,970 --> 00:16:26,660
we went from 16% of the variance explained

236
00:16:26,660 --> 00:16:31,290
in symptoms up to 22% of the variance
explained.

237
00:16:31,290 --> 00:16:35,330
So our model got better by adding in
another predictor.

238
00:16:35,330 --> 00:16:38,560
And the model might get even better if we
added in more, right?

239
00:16:38,560 --> 00:16:42,181
IMPACT has six measures five excluding
symptoms, so we

240
00:16:42,181 --> 00:16:47,280
could probably boost that percentage of
variance explained even more.

241
00:16:47,280 --> 00:16:48,980
but I just wanted to illustrate the
difference

242
00:16:48,980 --> 00:16:51,580
between simple and multiple.

243
00:16:54,160 --> 00:16:56,500
The trick with multiple regression, and
we'll cover this

244
00:16:56,500 --> 00:16:59,010
in detail next week in a full lecture on

245
00:16:59,010 --> 00:17:02,620
multiple regression, is you can't
visualize it all in

246
00:17:02,620 --> 00:17:05,950
one scatter plot, because now there are
two predictors.

247
00:17:05,950 --> 00:17:08,290
And imagine if we have say, six
predictors.

248
00:17:08,290 --> 00:17:10,990
You can't visualize it in one graphic.

249
00:17:10,990 --> 00:17:15,090
Here on the left is the scatter plot
relating impulse control to symptoms.

250
00:17:15,090 --> 00:17:18,290
On the right, verbal memory to symptoms.

251
00:17:18,290 --> 00:17:19,260
There is one way

252
00:17:19,260 --> 00:17:22,400
though, to capture it all in one scatter
plot.

253
00:17:23,840 --> 00:17:28,340
And again, that's through the model R and
R squared.

254
00:17:28,340 --> 00:17:31,780
Remember R is the multiple correlation
coefficient.

255
00:17:31,780 --> 00:17:35,560
It's the correlation between the predicted
scores and the observed scores and

256
00:17:35,560 --> 00:17:39,950
it tells you how well you're doing in
predicting the observed scores.

257
00:17:39,950 --> 00:17:44,540
So if I save my predicted scores in R, and
we'll show you how to do that in the Lab,

258
00:17:44,540 --> 00:17:50,090
then you could plot another scatter plot
with the predicted scores on

259
00:17:50,090 --> 00:17:53,980
the x axis and the actual observed scores
on the y axis.

260
00:17:53,980 --> 00:17:56,890
Again, I know from my output that that was
22%.

261
00:17:56,890 --> 00:17:59,820
If I take the square root of that, what
that indicates

262
00:17:59,820 --> 00:18:03,980
is the correlation between the observed
and the predicted scores is 0.47.

263
00:18:03,980 --> 00:18:10,530
And that was higher than any correlation I
saw in my correlation matrix because,

264
00:18:10,530 --> 00:18:15,400
I put in two predictors and the linear
combination of those two

265
00:18:15,400 --> 00:18:21,040
predictors does better at predicting the
outcome than any one predictor by itself.

266
00:18:21,040 --> 00:18:23,960
So that's the power of putting multiple
predictors

267
00:18:23,960 --> 00:18:26,590
in and that's the power of multiple
regression.

268
00:18:26,590 --> 00:18:30,210
So just a glimpse of that now, we'll get
to it in more detail next week.

269
00:18:31,680 --> 00:18:35,772
So to wrap up this segment, again, the
most important concepts to take away

270
00:18:35,772 --> 00:18:39,360
are just the distinction between simple
and multiple regression.

271
00:18:39,360 --> 00:18:42,300
The components of the regression equation.

272
00:18:42,300 --> 00:18:44,490
And the idea that we can build regression

273
00:18:44,490 --> 00:18:47,160
models and look at the model r squared,
which

274
00:18:47,160 --> 00:18:49,860
is the percentage of variance explained in
the outcome

275
00:18:49,860 --> 00:18:53,530
measure by that set of predictors in the
model.

